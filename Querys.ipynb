{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Querys.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Esta notebook se ocupará de realizar todas las peticiones a cada uno de los resources obtenidos en el colab anterior.\n",
        "\n",
        "No es tan simple como realizar una unica petición, a cada resource, dado que eso solo nos otorgaría 50 registros. \n",
        "Es necesario hacer varias peticiones, pidiendo 50 registros en cada una, hasta que se agoten los resultados, o hasta que lleguemos al limite de 10.000 registros."
      ],
      "metadata": {
        "id": "VONJDtuGyoBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos una librería para facilitar el uso de la API de MercadoLibre"
      ],
      "metadata": {
        "id": "tf01hRxlzg_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2m7YNFJQ7FAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e3dc88-9cd9-4dab-b6cd-0c31159a5cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/mercadolibre/python-sdk.git\n",
            "  Cloning https://github.com/mercadolibre/python-sdk.git to /tmp/pip-req-build-zoha1ehy\n",
            "  Running command git clone -q https://github.com/mercadolibre/python-sdk.git /tmp/pip-req-build-zoha1ehy\n",
            "Collecting urllib3>=1.25.6\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from meli==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from meli==3.0.0) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from meli==3.0.0) (2.8.2)\n",
            "Building wheels for collected packages: meli\n",
            "  Building wheel for meli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for meli: filename=meli-3.0.0-py3-none-any.whl size=39713 sha256=b3e9ee0d14649e1462d26615ca8609bec86a37674eca89989656635ad8fe3444\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x4simzqi/wheels/60/64/2d/4c5c8a03c8a655c3d499ecd487a15dc2e740aed5d6574b6305\n",
            "Successfully built meli\n",
            "Installing collected packages: urllib3, meli\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed meli-3.0.0 urllib3-1.26.7\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/mercadolibre/python-sdk.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para autenticarnos con la API, se debe acceder al siguiente [link](https://auth.mercadolibre.com.ar/authorization?response_type=code&client_id=96683996985285) , copiar el codigo que aparece en la URL, pegarlo en la celda de abajo, donde dice \"code\", y ejecutar la celda, para obtener el token, que será el que utilizaremos en cada peticion a la API.\n"
      ],
      "metadata": {
        "id": "6dyw23f8K9bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "import meli\n",
        "from meli.rest import ApiException\n",
        "from pprint import pprint\n",
        "\n",
        "configuration = meli.Configuration(\n",
        "    host = \"https://api.mercadolibre.com\"\n",
        ")\n",
        "\n",
        "with meli.ApiClient() as api_client:\n",
        "    api_instance = meli.OAuth20Api(api_client)\n",
        "    grant_type = 'authorization_code' # str\n",
        "    client_id = '96683996985285' # Your client_id\n",
        "    client_secret = 'nMeP0YOMz9ZW0ujUdp9MEdV1Spr23vWR' # Your client_secret\n",
        "    redirect_uri = 'https://www.google.com' # Your redirect_uri\n",
        "    code = 'TG-61cb3a707b998c001c612aa5-204954233' # The parameter CODE\n",
        "    refresh_token = 'refresh_token_example' # Your refresh_token\n",
        "try:\n",
        "    api_response = api_instance.get_token(grant_type=grant_type, client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri, code=code, refresh_token=refresh_token)\n",
        "    access_token = api_response[\"access_token\"]\n",
        "except ApiException as e:\n",
        "    print(\"Exception when calling OAuth20Api->get_token: %s\\n\" % e)"
      ],
      "metadata": {
        "id": "IpAZyGVVDIZJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encapsulamos la funcion get de MercadoLibre, con algunos parametros de utilidad.\n",
        "\n",
        "Offset es el indice del primer registro que queremos consultar. Ej: Si es 0, nos traerá el primer registro que la API tiene disponible para el Resource que estamos consultando. \n",
        "\n",
        "Limit es la cantidad de registros que nos traerá la API. El maximo es 50."
      ],
      "metadata": {
        "id": "LExfvQkHz5uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_request(resource, offset=0, limit=50):\n",
        "    api_instance = meli.RestClientApi(api_client)\n",
        "    try:\n",
        "        return api_instance.resource_get(resource+\"&offset=\"+str(offset)+\"&limit=\"+str(limit), access_token)\n",
        "    except ApiException as e:\n",
        "      print(\"Exception when calling RestClientApi->resource_get: %s\\n\" % e)"
      ],
      "metadata": {
        "id": "U_YR-xd_ScnZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a descargar el archivo de resources del bucket, subido en la notebook anterior. De la misma forma que antes, declaramos dos variables, una con el nombre del proyecto y la otra con el nombre del bucket, y nos autenticamos.\n",
        "\n",
        "Y luego, copiamos del bucket al filesystem, el archivo resources.pkl"
      ],
      "metadata": {
        "id": "dIQu8TmS0Bu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'cryptic-opus-335323'\n",
        "bucket_name = 'bdm-unlu'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gsutil cp gs://{bucket_name}/resources/resources.pkl resources.pkl "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u3skPZqIpq0",
        "outputId": "1ddab239-4906-4c56-b48f-cfffe8e33a29"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://bdm-unlu/resources/resources.pkl...\n",
            "/ [1 files][427.8 KiB/427.8 KiB]                                                \n",
            "Operation completed over 1 objects/427.8 KiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos la libreria utilizada anteriormente para leer el archivo en binario, y transformarlo a una lista nuevamente."
      ],
      "metadata": {
        "id": "bTnR7yfj0SXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "file_name = \"resources.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"rb\")\n",
        "\n",
        "resources_with_neighborhood = pickle.load(open_file)"
      ],
      "metadata": {
        "id": "sJNCJgu-R2H6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que contenga la cantidad de resources que debe tener"
      ],
      "metadata": {
        "id": "mNNN3mp70cUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(resources_with_neighborhood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJvo84piEalS",
        "outputId": "3deebdf4-df03-4346-eb7c-c2b185b4d370"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2577"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y esta es la funcion core de esta notebook. Le llega como parametro un resource, y lo que va a hacer es realizar peticiones a la api, pidiendo de a 50 registros, arrancando por el primero.\n",
        "\n",
        "Cuando la API le conteste con una cantidad de registros inferior a 50, quiere decir que son los últimos que tiene para entregar, entonces pasa a Falso una variable, y deja de solicitar registros.\n",
        "\n",
        "Y en el otro momento que esta variable pasa a tener valor Falso, es cuando el offset, llegó a 10.000, que es el máximo que permite MercadoLibre.\n",
        "\n",
        "Todos los registros que la API le contesta en el mientras tanto, los va agregando a una lista, que va a ser la que devuelva cuando deje de solicitar registros."
      ],
      "metadata": {
        "id": "GF3tTM1z0jb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results(resource_with_neighborhood):\n",
        "  results = []\n",
        "  records_remaining = True;\n",
        "  offset = 0\n",
        "  while records_remaining:\n",
        "    api_response = get_request(resource_with_neighborhood, offset, 50)[\"results\"]\n",
        "    results.extend(api_response)\n",
        "    offset += 50\n",
        "    if len(api_response) < 50 or offset == 10000:\n",
        "      records_remaining = False\n",
        "  return results"
      ],
      "metadata": {
        "id": "9A3c4d3SpcBX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez codificada la funcion anterior, nos encontramos con 2 problemas, que ya están resueltos pero que vale la pena comentarlos.\n",
        "\n",
        "1: Haciendo las peticiones secuencialmente, iterando por cada resource, tardaba muchisimo tiempo, por lo que optamos en usar Threads, en total 25 workers, que realizan las peticiones en un tiempo de 3 minutos.\n",
        "\n",
        "2: Si cada worker guardaba en memoria los resultados que iba obteniendo de la API, desbordaban la memoria RAM de la notebook (12gb), por lo que optamos en guardar los resultados en un archivo, para pasar esa carga al disco, y no a la memoria RAM.\n",
        "\n",
        "Abrimos el archivo mencionado anteriormente, en modo escritura binaria."
      ],
      "metadata": {
        "id": "CTYI_UXV1c-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "open_file = open(\"test.pkl\", \"wb\")"
      ],
      "metadata": {
        "id": "3EdySbsaI_ny"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos una funcion que agrega al archivo, un resultado, utilizando la libreria pickle."
      ],
      "metadata": {
        "id": "bXUotxYf2gyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def append_to_file(result):\n",
        "  pickle.dump(result, open_file)"
      ],
      "metadata": {
        "id": "XT0M7JWLEj7T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bloque de código levanta los 25 workers, cuyo punto de procesamiento es la funcion core mencionada anteriormente.\n",
        "\n",
        "Se agregan a una cola cada uno de los resources, se levantan 25 threads con un worker cada uno, que consumen de la cola y realizan las peticiones utilizando la funcion get_results(), y guardan los resultados en el archivo.\n",
        "Además, para verificar, llevan un conteo de la cantidad de registros consultados."
      ],
      "metadata": {
        "id": "pNbeZkCX4IKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue, time, urllib.request\n",
        "from threading import Thread\n",
        "\n",
        "def perform_web_requests(addresses, no_workers):\n",
        "    class Worker(Thread):\n",
        "        def __init__(self, request_queue):\n",
        "            Thread.__init__(self)\n",
        "            self.queue = request_queue\n",
        "            self.errors = []\n",
        "            self.counter = 0\n",
        "\n",
        "        def run(self):\n",
        "            while True:\n",
        "                content = self.queue.get()\n",
        "                if content == \"\":\n",
        "                    break\n",
        "                try:\n",
        "                  results = get_results(content)\n",
        "                  self.counter += len(results)\n",
        "                  append_to_file(results)\n",
        "                except Exception as e:\n",
        "                  self.errors.append(e)\n",
        "                self.queue.task_done()\n",
        "\n",
        "    q = queue.Queue()\n",
        "    for url in addresses:\n",
        "        q.put(url)\n",
        "\n",
        "    workers = []\n",
        "    for _ in range(no_workers):\n",
        "        worker = Worker(q)\n",
        "        worker.start()\n",
        "        workers.append(worker)\n",
        "\n",
        "    for _ in workers:\n",
        "        q.put(\"\")\n",
        "\n",
        "    for worker in workers:\n",
        "        worker.join()\n",
        "\n",
        "    e = []\n",
        "    record_count = 0\n",
        "    for worker in workers:\n",
        "        e.extend(worker.errors)\n",
        "        record_count += worker.counter\n",
        "\n",
        "    return [e, record_count]\n",
        "\n",
        "errors, record_count = perform_web_requests(resources_with_neighborhood, 25)"
      ],
      "metadata": {
        "id": "H6rugUtu-uXe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que no hubo ningún error en los workers"
      ],
      "metadata": {
        "id": "0imDRCAT4zMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEzdgA5rN6eI",
        "outputId": "3a084403-dd15-4e63-b491-f926ce53f8aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos la cantidad de registros obtenidos por los threads"
      ],
      "metadata": {
        "id": "_dqs3dWy43SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "record_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYugjvBi3B2b",
        "outputId": "1640eca7-06b8-45ed-8b45-7fa2039f6285"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "308017"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_file.close()"
      ],
      "metadata": {
        "id": "Ht3fo45Q0p0F"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copiamos el archivo donde se almacenaron todos los registros, al bucket, en el path bdm-unlu/querys/results.pkl. Para lueo consumirlo en la notebook de [Attributes](https://colab.research.google.com/drive/1HzNmYKuCXJXwCriNWZs01-j2mHe8iveG)"
      ],
      "metadata": {
        "id": "Sw0Ad9K946sR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp test.pkl gs://{bucket_name}/querys/results.pkl"
      ],
      "metadata": {
        "id": "VTKu1rzphyHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf23c77f-f78b-4402-c40e-40f86fa4f3e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://test.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/  1.4 GiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "\\\n",
            "Operation completed over 1 objects/1.4 GiB.                                      \n"
          ]
        }
      ]
    }
  ]
}